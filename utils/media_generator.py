"""
åª’ä½“ç”Ÿæˆå·¥å…·æ¨¡å—
åŒ…å«å›¾ç‰‡å’ŒéŸ³é¢‘ç”Ÿæˆçš„é€šç”¨å‡½æ•°ï¼Œæ”¯æŒå¹¶å‘å¤„ç†
"""
import os
import json
import concurrent.futures
from typing import List, Dict, Any, Tuple
from utils.comfyui import generate_image
from utils.tts import generate_audio_for_script


class MediaGenerationResult:
    """åª’ä½“ç”Ÿæˆç»“æœç±»"""
    def __init__(self):
        self.generated_images = []
        self.failed_images = []
        self.generated_audio = []
        self.generated_srt = []
        self.failed_audio = []
    
    def add_image_success(self, filename: str):
        """æ·»åŠ æˆåŠŸç”Ÿæˆçš„å›¾ç‰‡"""
        self.generated_images.append(filename)
    
    def add_image_failure(self, filename: str, error: str = ""):
        """æ·»åŠ ç”Ÿæˆå¤±è´¥çš„å›¾ç‰‡"""
        error_msg = f"{filename}" + (f" (é”™è¯¯: {error})" if error else "")
        self.failed_images.append(error_msg)
    
    def add_audio_success(self, audio_file: str, srt_file: str):
        """æ·»åŠ æˆåŠŸç”Ÿæˆçš„éŸ³é¢‘å’Œå­—å¹•"""
        self.generated_audio.append(audio_file)
        self.generated_srt.append(srt_file)
    
    def add_audio_failure(self, audio_file: str, srt_file: str, error: str = ""):
        """æ·»åŠ ç”Ÿæˆå¤±è´¥çš„éŸ³é¢‘å’Œå­—å¹•"""
        error_msg = f"{audio_file} / {srt_file}" + (f" (é”™è¯¯: {error})" if error else "")
        self.failed_audio.append(error_msg)
    
    def get_statistics(self, total_count: int) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_scenes": total_count,
            "image_success": len(self.generated_images),
            "image_failed": len(self.failed_images),
            "audio_success": len(self.generated_audio),
            "audio_failed": len(self.failed_audio),
            "image_success_rate": (len(self.generated_images) / total_count * 100) if total_count > 0 else 0,
            "audio_success_rate": (len(self.generated_audio) / total_count * 100) if total_count > 0 else 0
        }


def validate_scenes_scripts(scenes_scripts: List[Dict]) -> List[Dict]:
    """
    éªŒè¯åœºæ™¯è„šæœ¬æ•°æ®çš„æœ‰æ•ˆæ€§ï¼Œç¡®ä¿éŸ³è‰²ç±»å‹æ­£ç¡®
    
    Args:
        scenes_scripts: åœºæ™¯è„šæœ¬åˆ—è¡¨
    
    Returns:
        éªŒè¯å¹¶ä¿®æ­£åçš„åœºæ™¯è„šæœ¬åˆ—è¡¨
    """
    valid_voice_types = {"male", "female", "narrator"}
    
    for scene in scenes_scripts:
        voice_type = scene.get("voice_type", "narrator")
        if voice_type not in valid_voice_types:
            print(f"è­¦å‘Šï¼šåœºæ™¯ {scene.get('scene_index')} çš„éŸ³è‰²ç±»å‹ '{voice_type}' æ— æ•ˆï¼Œå·²è°ƒæ•´ä¸º 'narrator'")
            scene["voice_type"] = "narrator"
    
    return scenes_scripts


def load_scenes_scripts(json_path: str) -> Tuple[List[Dict], str]:
    """
    åŠ è½½åœºæ™¯è„šæœ¬é…ç½®æ–‡ä»¶
    
    Args:
        json_path: JSONæ–‡ä»¶è·¯å¾„
    
    Returns:
        (åœºæ™¯è„šæœ¬åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)ï¼Œå¦‚æœæˆåŠŸåˆ™é”™è¯¯ä¿¡æ¯ä¸ºç©ºå­—ç¬¦ä¸²
    """
    if not os.path.exists(json_path):
        return [], f"âŒ æœªæ‰¾åˆ° {json_path}ï¼Œè¯·å…ˆç”Ÿæˆåˆ†é•œå’Œè„šæœ¬"
    
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            scenes_scripts = json.load(f)
        
        if not scenes_scripts:
            return [], f"âŒ {json_path} ä¸ºç©º"
        
        # éªŒè¯å’Œä¿®æ­£æ•°æ®
        scenes_scripts = validate_scenes_scripts(scenes_scripts)
        return scenes_scripts, ""
        
    except json.JSONDecodeError as e:
        return [], f"âŒ JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}"
    except Exception as e:
        return [], f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"


def generate_single_image(item: Dict, images_dir: str) -> Dict[str, Any]:
    """
    ç”Ÿæˆå•ä¸ªå›¾ç‰‡
    
    Args:
        item: åœºæ™¯é…ç½®é¡¹
        images_dir: å›¾ç‰‡è¾“å‡ºç›®å½•
    
    Returns:
        ç”Ÿæˆç»“æœå­—å…¸
    """
    try:
        scene_index = item.get("scene_index")
        scene_content = item.get("scene_prompt", "").strip()
        image_path = os.path.join(images_dir, f"scene_{scene_index}.png")
        
        print(f"ğŸ¨ æ­£åœ¨ç”Ÿæˆç¬¬{scene_index}å¼ å›¾ç‰‡...")
        result = generate_image(prompt_text=scene_content, save_path=image_path)
        
        if result and os.path.exists(image_path):
            print(f"âœ… ç¬¬{scene_index}å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: scene_{scene_index}.png")
            return {
                "success": True, 
                "file": f"scene_{scene_index}.png", 
                "index": scene_index
            }
        else:
            print(f"âŒ ç¬¬{scene_index}å¼ å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
            return {
                "success": False, 
                "file": f"scene_{scene_index}.png", 
                "index": scene_index, 
                "error": "ç”Ÿæˆå¤±è´¥"
            }
    except Exception as e:
        print(f"âŒ ç¬¬{scene_index}å¼ å›¾ç‰‡ç”Ÿæˆå¼‚å¸¸: {str(e)}")
        return {
            "success": False, 
            "file": f"scene_{scene_index}.png", 
            "index": scene_index, 
            "error": str(e)
        }


def generate_single_audio(item: Dict, audio_dir: str, srt_dir: str, temp_dir: str) -> Dict[str, Any]:
    """
    ç”Ÿæˆå•ä¸ªéŸ³é¢‘å’Œå­—å¹•
    
    Args:
        item: åœºæ™¯é…ç½®é¡¹
        audio_dir: éŸ³é¢‘è¾“å‡ºç›®å½•
        srt_dir: å­—å¹•è¾“å‡ºç›®å½•
        temp_dir: ä¸´æ—¶æ–‡ä»¶ç›®å½•
    
    Returns:
        ç”Ÿæˆç»“æœå­—å…¸
    """
    try:
        scene_index = item.get("scene_index")
        script_content = item.get("scene_script", "").strip()
        voice_type = item.get("voice_type", "narrator")
        audio_path = os.path.join(audio_dir, f"audio_{scene_index}.mp3")
        srt_path = os.path.join(srt_dir, f"srt_{scene_index}.srt")
        
        print(f"ğŸµ æ­£åœ¨ç”Ÿæˆç¬¬{scene_index}ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆéŸ³è‰²ï¼š{voice_type}ï¼‰...")
        
        # åˆ›å»ºä¸´æ—¶è„šæœ¬æ–‡ä»¶
        tmp_script_path = os.path.join(temp_dir, f"tmp_script_{scene_index}.txt")
        with open(tmp_script_path, "w", encoding="utf-8") as ftmp:
            ftmp.write(script_content)
        
        # ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•
        result = generate_audio_for_script(tmp_script_path, audio_path, srt_path, voice_type=voice_type)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(tmp_script_path):
            os.remove(tmp_script_path)
        
        if "å·²ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶" in result or "éŸ³é¢‘å’Œå­—å¹•ç”Ÿæˆå®Œæˆ" in result:
            print(f"âœ… ç¬¬{scene_index}ä¸ªéŸ³é¢‘å’Œå­—å¹•ç”ŸæˆæˆåŠŸ")
            return {
                "success": True, 
                "audio": f"audio_{scene_index}.mp3", 
                "srt": f"srt_{scene_index}.srt", 
                "index": scene_index
            }
        else:
            print(f"âŒ ç¬¬{scene_index}ä¸ªéŸ³é¢‘ç”Ÿæˆå¤±è´¥")
            return {
                "success": False, 
                "audio": f"audio_{scene_index}.mp3", 
                "srt": f"srt_{scene_index}.srt", 
                "index": scene_index, 
                "error": "ç”Ÿæˆå¤±è´¥"
            }
    except Exception as e:
        # ç¡®ä¿æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        tmp_script_path = os.path.join(temp_dir, f"tmp_script_{scene_index}.txt")
        if os.path.exists(tmp_script_path):
            os.remove(tmp_script_path)
        
        print(f"âŒ ç¬¬{scene_index}ä¸ªéŸ³é¢‘ç”Ÿæˆå¼‚å¸¸: {str(e)}")
        return {
            "success": False, 
            "audio": f"audio_{scene_index}.mp3", 
            "srt": f"srt_{scene_index}.srt", 
            "index": scene_index, 
            "error": str(e)
        }


def generate_media_concurrent(scenes_scripts: List[Dict], output_dirs: Dict[str, str], 
                            max_workers: int = 4) -> MediaGenerationResult:
    """
    å¹¶å‘ç”Ÿæˆå›¾ç‰‡å’ŒéŸ³é¢‘
    
    Args:
        scenes_scripts: åœºæ™¯è„šæœ¬åˆ—è¡¨
        output_dirs: è¾“å‡ºç›®å½•å­—å…¸ï¼ŒåŒ…å« images_dir, audio_dir, srt_dir, temp_dir
        max_workers: æœ€å¤§å¹¶å‘æ•°
    
    Returns:
        MediaGenerationResult: ç”Ÿæˆç»“æœ
    """
    result = MediaGenerationResult()
    
    # ç¡®ä¿æ‰€æœ‰è¾“å‡ºç›®å½•å­˜åœ¨
    for dir_path in output_dirs.values():
        os.makedirs(dir_path, exist_ok=True)
    
    print(f"ğŸš€ å¼€å§‹å¹¶å‘ç”Ÿæˆ{len(scenes_scripts)}ä¸ªåœºæ™¯çš„å›¾ç‰‡å’ŒéŸ³é¢‘...")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰å›¾ç‰‡ç”Ÿæˆä»»åŠ¡
        image_futures = [
            executor.submit(generate_single_image, item, output_dirs["images_dir"]) 
            for item in scenes_scripts
        ]
        
        # æäº¤æ‰€æœ‰éŸ³é¢‘ç”Ÿæˆä»»åŠ¡
        audio_futures = [
            executor.submit(generate_single_audio, item, 
                          output_dirs["audio_dir"], 
                          output_dirs["srt_dir"], 
                          output_dirs["temp_dir"]) 
            for item in scenes_scripts
        ]
        
        # æ”¶é›†å›¾ç‰‡ç”Ÿæˆç»“æœ
        for future in concurrent.futures.as_completed(image_futures):
            try:
                task_result = future.result()
                if task_result["success"]:
                    result.add_image_success(task_result["file"])
                else:
                    error_info = task_result.get("error", "æœªçŸ¥é”™è¯¯")
                    result.add_image_failure(task_result["file"], error_info)
            except Exception as e:
                result.add_image_failure("unknown_file", str(e))
        
        # æ”¶é›†éŸ³é¢‘ç”Ÿæˆç»“æœ
        for future in concurrent.futures.as_completed(audio_futures):
            try:
                task_result = future.result()
                if task_result["success"]:
                    result.add_audio_success(task_result["audio"], task_result["srt"])
                else:
                    error_info = task_result.get("error", "æœªçŸ¥é”™è¯¯")
                    result.add_audio_failure(task_result["audio"], task_result["srt"], error_info)
            except Exception as e:
                result.add_audio_failure("unknown_audio", "unknown_srt", str(e))
    
    return result


def generate_media_report(chapter_num: int, result: MediaGenerationResult, 
                         total_scenes: int) -> str:
    """
    ç”Ÿæˆåª’ä½“æ–‡ä»¶ç”Ÿæˆç»“æœæŠ¥å‘Š
    
    Args:
        chapter_num: ç« èŠ‚å·
        result: ç”Ÿæˆç»“æœ
        total_scenes: æ€»åœºæ™¯æ•°
    
    Returns:
        æ ¼å¼åŒ–çš„æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    stats = result.get_statistics(total_scenes)
    
    report = f"""
ğŸ“Š ç¬¬{chapter_num}ç« åª’ä½“æ–‡ä»¶å¹¶å‘ç”Ÿæˆå®ŒæˆæŠ¥å‘Š:
==========================================
ğŸ–¼ï¸ å›¾ç‰‡ç”Ÿæˆç»Ÿè®¡:
- æ€»åœºæ™¯æ•°: {stats['total_scenes']}
- æˆåŠŸç”Ÿæˆ: {stats['image_success']}å¼ 
- ç”Ÿæˆå¤±è´¥: {stats['image_failed']}å¼ 
- æˆåŠŸç‡: {stats['image_success_rate']:.1f}%

ğŸ”Š éŸ³é¢‘ç”Ÿæˆç»Ÿè®¡:
- æ€»è„šæœ¬æ•°: {stats['total_scenes']}
- æˆåŠŸç”Ÿæˆ: {stats['audio_success']}ä¸ªéŸ³é¢‘
- ç”Ÿæˆå¤±è´¥: {stats['audio_failed']}ä¸ªéŸ³é¢‘
- æˆåŠŸç‡: {stats['audio_success_rate']:.1f}%

âœ… æˆåŠŸç”Ÿæˆçš„å›¾ç‰‡:
{chr(10).join(f'  - {img}' for img in result.generated_images)}

âœ… æˆåŠŸç”Ÿæˆçš„éŸ³é¢‘:
{chr(10).join(f'  - {audio}' for audio in result.generated_audio)}

âœ… æˆåŠŸç”Ÿæˆçš„å­—å¹•:
{chr(10).join(f'  - {srt}' for srt in result.generated_srt)}
"""
    
    if result.failed_images:
        report += f"""
âŒ ç”Ÿæˆå¤±è´¥çš„å›¾ç‰‡:
{chr(10).join(f'  - {img}' for img in result.failed_images)}
"""
    
    if result.failed_audio:
        report += f"""
âŒ ç”Ÿæˆå¤±è´¥çš„éŸ³é¢‘:
{chr(10).join(f'  - {audio}' for audio in result.failed_audio)}
"""
    
    return report


def setup_chapter_directories(chapter_num: int) -> Dict[str, str]:
    """
    è®¾ç½®ç« èŠ‚è¾“å‡ºç›®å½•
    
    Args:
        chapter_num: ç« èŠ‚å·
    
    Returns:
        åŒ…å«æ‰€æœ‰ç›®å½•è·¯å¾„çš„å­—å…¸
    """
    output_dir = f"output/chapters/chapter_{chapter_num}"
    
    return {
        "output_dir": output_dir,
        "images_dir": os.path.join(output_dir, "images"),
        "audio_dir": os.path.join(output_dir, "audio"),
        "srt_dir": os.path.join(output_dir, "srt"),
        "temp_dir": output_dir,
        "json_path": os.path.join(output_dir, "scenes_scripts.json")
    }
