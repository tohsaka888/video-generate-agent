"""
åª’ä½“ç”Ÿæˆå·¥å…·æ¨¡å—
åŒ…å«å›¾ç‰‡å’ŒéŸ³é¢‘ç”Ÿæˆçš„é€šç”¨å‡½æ•°ï¼Œæ”¯æŒå¹¶å‘å¤„ç†
"""
import os
import json
import threading
from typing import List, Dict, Any, Tuple
from utils.comfyui import generate_image
from utils.tts import generate_audio_for_script


class MediaGenerationResult:
    """åª’ä½“ç”Ÿæˆç»“æžœç±»"""
    def __init__(self):
        self.generated_images = []
        self.failed_images = []
        self.generated_audio = []
        self.generated_srt = []
        self.failed_audio = []
    
    def add_image_success(self, filename: str):
        self.generated_images.append(filename)
    
    def add_image_failure(self, filename: str, error: str = ""):
        error_msg = f"{filename}" + (f" (é”™è¯¯: {error})" if error else "")
        self.failed_images.append(error_msg)
    
    def add_audio_success(self, audio_file: str, srt_file: str):
        self.generated_audio.append(audio_file)
        self.generated_srt.append(srt_file)
    
    def add_audio_failure(self, audio_file: str, srt_file: str, error: str = ""):
        error_msg = f"{audio_file} / {srt_file}" + (f" (é”™è¯¯: {error})" if error else "")
        self.failed_audio.append(error_msg)


def validate_scenes_scripts(scenes_scripts: List[Dict]) -> List[Dict]:
    valid_voice_types = {"male", "female", "narrator"}
    for scene in scenes_scripts:
        voice_type = scene.get("voice_type", "narrator")
        if voice_type not in valid_voice_types:
            print(f"è­¦å‘Šï¼šåœºæ™¯ {scene.get('scene_index')} çš„éŸ³è‰²ç±»åž‹ '{voice_type}' æ— æ•ˆï¼Œå·²è°ƒæ•´ä¸º 'narrator'")
            scene["voice_type"] = "narrator"
    return scenes_scripts


def load_scenes_scripts(json_path: str) -> Tuple[List[Dict], str]:
    if not os.path.exists(json_path):
        return [], f"âŒ æœªæ‰¾åˆ° {json_path}ï¼Œè¯·å…ˆç”Ÿæˆåˆ†é•œå’Œè„šæœ¬"
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            scenes_scripts = json.load(f)
        if not scenes_scripts:
            return [], f"âŒ {json_path} ä¸ºç©º"
        scenes_scripts = validate_scenes_scripts(scenes_scripts)
        return scenes_scripts, ""
    except json.JSONDecodeError as e:
        return [], f"âŒ JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}"
    except Exception as e:
        return [], f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"


def generate_single_image(item: Dict, images_dir: str) -> Dict[str, Any]:
    try:
        scene_index = item.get("scene_index")
        scene_content = item.get("scene_prompt", "").strip()
        image_path = os.path.join(images_dir, f"scene_{scene_index}.png")
        print(f"ðŸŽ¨ æ­£åœ¨ç”Ÿæˆç¬¬{scene_index}å¼ å›¾ç‰‡...")
        result = generate_image(prompt_text=scene_content, save_path=image_path)
        if result and os.path.exists(image_path):
            print(f"âœ… ç¬¬{scene_index}å¼ å›¾ç‰‡ç”ŸæˆæˆåŠŸ: scene_{scene_index}.png")
            return {"success": True, "file": f"scene_{scene_index}.png", "index": scene_index}
        else:
            print(f"âŒ ç¬¬{scene_index}å¼ å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
            return {"success": False, "file": f"scene_{scene_index}.png", "index": scene_index, "error": "ç”Ÿæˆå¤±è´¥"}
    except Exception as e:
        print(f"âŒ ç¬¬{scene_index}å¼ å›¾ç‰‡ç”Ÿæˆå¼‚å¸¸: {str(e)}")
        return {"success": False, "file": f"scene_{scene_index}.png", "index": scene_index, "error": str(e)}


def generate_single_audio(item: Dict, audio_dir: str, srt_dir: str, temp_dir: str) -> Dict[str, Any]:
    try:
        scene_index = item.get("scene_index")
        script_content = item.get("scene_script", "").strip()
        voice_type = item.get("voice_type", "narrator")
        audio_path = os.path.join(audio_dir, f"audio_{scene_index}.mp3")
        srt_path = os.path.join(srt_dir, f"srt_{scene_index}.srt")
        print(f"ðŸŽµ æ­£åœ¨ç”Ÿæˆç¬¬{scene_index}ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆéŸ³è‰²ï¼š{voice_type}ï¼‰...")
        tmp_script_path = os.path.join(temp_dir, f"tmp_script_{scene_index}.txt")
        with open(tmp_script_path, "w", encoding="utf-8") as ftmp:
            ftmp.write(script_content)
        result = generate_audio_for_script(tmp_script_path, audio_path, srt_path, voice_type=voice_type)
        if os.path.exists(tmp_script_path):
            os.remove(tmp_script_path)
        if "å·²ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶" in result or "éŸ³é¢‘å’Œå­—å¹•ç”Ÿæˆå®Œæˆ" in result:
            print(f"âœ… ç¬¬{scene_index}ä¸ªéŸ³é¢‘å’Œå­—å¹•ç”ŸæˆæˆåŠŸ")
            return {"success": True, "audio": f"audio_{scene_index}.mp3", "srt": f"srt_{scene_index}.srt", "index": scene_index}
        else:
            print(f"âŒ ç¬¬{scene_index}ä¸ªéŸ³é¢‘ç”Ÿæˆå¤±è´¥")
            return {"success": False, "audio": f"audio_{scene_index}.mp3", "srt": f"srt_{scene_index}.srt", "index": scene_index, "error": "ç”Ÿæˆå¤±è´¥"}
    except Exception as e:
        tmp_script_path = os.path.join(temp_dir, f"tmp_script_{scene_index}.txt")
        if os.path.exists(tmp_script_path):
            os.remove(tmp_script_path)
        print(f"âŒ ç¬¬{scene_index}ä¸ªéŸ³é¢‘ç”Ÿæˆå¼‚å¸¸: {str(e)}")
        return {"success": False, "audio": f"audio_{scene_index}.mp3", "srt": f"srt_{scene_index}.srt", "index": scene_index, "error": str(e)}


def generate_media_concurrent(scenes_scripts: List[Dict], output_dirs: Dict[str, str]) -> MediaGenerationResult:
    """
    å¹¶å‘ç”Ÿæˆå›¾ç‰‡å’ŒéŸ³é¢‘ï¼ˆåˆ†åˆ«ä¸ºä¸¤ä¸ªé˜Ÿåˆ—ï¼Œé˜Ÿåˆ—å†…é¡ºåºæ‰§è¡Œï¼‰
    Args:
        scenes_scripts: åœºæ™¯è„šæœ¬åˆ—è¡¨
        output_dirs: è¾“å‡ºç›®å½•å­—å…¸ï¼ŒåŒ…å« images_dir, audio_dir, srt_dir, temp_dir
    Returns:
        MediaGenerationResult: ç”Ÿæˆç»“æžœ
    """
    result = MediaGenerationResult()
    for dir_path in output_dirs.values():
        os.makedirs(dir_path, exist_ok=True)
    print(f"ðŸš€ å¼€å§‹ç”Ÿæˆ{len(scenes_scripts)}ä¸ªåœºæ™¯çš„å›¾ç‰‡å’ŒéŸ³é¢‘ï¼ˆå›¾ç‰‡/éŸ³é¢‘åˆ†åˆ«é˜Ÿåˆ—ï¼‰...")

    def image_worker():
        for item in scenes_scripts:
            task_result = generate_single_image(item, output_dirs["images_dir"])
            if task_result["success"]:
                result.add_image_success(task_result["file"])
            else:
                error_info = task_result.get("error", "æœªçŸ¥é”™è¯¯")
                result.add_image_failure(task_result["file"], error_info)

    def audio_worker():
        for item in scenes_scripts:
            task_result = generate_single_audio(item, output_dirs["audio_dir"], output_dirs["srt_dir"], output_dirs["temp_dir"])
            if task_result["success"]:
                result.add_audio_success(task_result["audio"], task_result["srt"])
            else:
                error_info = task_result.get("error", "æœªçŸ¥é”™è¯¯")
                result.add_audio_failure(task_result["audio"], task_result["srt"], error_info)

    t_img = threading.Thread(target=image_worker)
    t_aud = threading.Thread(target=audio_worker)
    t_img.start()
    t_aud.start()
    t_img.join()
    t_aud.join()
    return result


def generate_media_report(chapter_num: int, result: MediaGenerationResult, total_scenes: int) -> str:
    """
    ç”Ÿæˆåª’ä½“æ–‡ä»¶ç”Ÿæˆç»“æžœæŠ¥å‘Š
    Args:
        chapter_num: ç« èŠ‚å·
        result: ç”Ÿæˆç»“æžœ
        total_scenes: æ€»åœºæ™¯æ•°
    Returns:
        æ ¼å¼åŒ–çš„æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    image_success = len(result.generated_images)
    image_failed = len(result.failed_images)
    audio_success = len(result.generated_audio)
    audio_failed = len(result.failed_audio)
    image_success_rate = (image_success / total_scenes * 100) if total_scenes > 0 else 0
    audio_success_rate = (audio_success / total_scenes * 100) if total_scenes > 0 else 0
    report = f"""
ðŸ“Š ç¬¬{chapter_num}ç« åª’ä½“æ–‡ä»¶ç”Ÿæˆå®ŒæˆæŠ¥å‘Š:
==========================================
ðŸ–¼ï¸ å›¾ç‰‡ç”Ÿæˆç»Ÿè®¡:
- æ€»åœºæ™¯æ•°: {total_scenes}
- æˆåŠŸç”Ÿæˆ: {image_success}å¼ 
- ç”Ÿæˆå¤±è´¥: {image_failed}å¼ 
- æˆåŠŸçŽ‡: {image_success_rate:.1f}%

ðŸ”Š éŸ³é¢‘ç”Ÿæˆç»Ÿè®¡:
- æ€»è„šæœ¬æ•°: {total_scenes}
- æˆåŠŸç”Ÿæˆ: {audio_success}ä¸ªéŸ³é¢‘
- ç”Ÿæˆå¤±è´¥: {audio_failed}ä¸ªéŸ³é¢‘
- æˆåŠŸçŽ‡: {audio_success_rate:.1f}%

âœ… æˆåŠŸç”Ÿæˆçš„å›¾ç‰‡:
{chr(10).join(f'  - {img}' for img in result.generated_images)}

âœ… æˆåŠŸç”Ÿæˆçš„éŸ³é¢‘:
{chr(10).join(f'  - {audio}' for audio in result.generated_audio)}

âœ… æˆåŠŸç”Ÿæˆçš„å­—å¹•:
{chr(10).join(f'  - {srt}' for srt in result.generated_srt)}
"""
    if result.failed_images:
        report += f"""
âŒ ç”Ÿæˆå¤±è´¥çš„å›¾ç‰‡:
{chr(10).join(f'  - {img}' for img in result.failed_images)}
"""
    if result.failed_audio:
        report += f"""
âŒ ç”Ÿæˆå¤±è´¥çš„éŸ³é¢‘:
{chr(10).join(f'  - {audio}' for audio in result.failed_audio)}
"""
    return report


def setup_chapter_directories(chapter_num: int) -> Dict[str, str]:
    output_dir = f"output/chapters/chapter_{chapter_num}"
    return {
        "output_dir": output_dir,
        "images_dir": os.path.join(output_dir, "images"),
        "audio_dir": os.path.join(output_dir, "audio"),
        "srt_dir": os.path.join(output_dir, "srt"),
        "temp_dir": output_dir,
        "json_path": os.path.join(output_dir, "scenes_scripts.json")
    }
