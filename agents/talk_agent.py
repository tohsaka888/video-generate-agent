import os
import json
from dataclasses import dataclass
from typing import List, Literal
from pydantic_ai import Agent, RunContext
from utils.llm import chat_model
from utils.tts import (
    generate_sentence_audio_and_srt, 
    merge_audio_files, 
    merge_srt_files
)


@dataclass
class TalkAgentDeps:
    scene_id: int = 1  # åœºæ™¯ID


@dataclass
class TalkAgentOutput:
    text: str = ""
    voice_type: Literal["male", "female", "narrator"] = "narrator"


talk_agent = Agent(
    model=chat_model,
    deps_type=TalkAgentDeps,
    output_type=List[TalkAgentOutput],
)


@talk_agent.instructions
def analyze_script_and_generate_audio(ctx: RunContext[TalkAgentDeps]) -> str:
    """åˆ†æè„šæœ¬å†…å®¹ï¼Œç”Ÿæˆè¯­éŸ³å’Œå­—å¹•æ–‡ä»¶"""
    scene_id = ctx.deps.scene_id
    
    return f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¯­éŸ³åˆ†æå¸ˆï¼Œè´Ÿè´£ä¸ºåœºæ™¯ {scene_id} çš„è„šæœ¬ç”Ÿæˆè¯­éŸ³å’Œå­—å¹•ã€‚

å·¥ä½œæµç¨‹ï¼š
1. è°ƒç”¨ read_scene_script å·¥å…·è¯»å–åœºæ™¯è„šæœ¬
2. åˆ†æè„šæœ¬å†…å®¹ï¼Œå°†æ–‡æœ¬æŒ‰è¯­ä¹‰æ‹†åˆ†æˆå¥å­
3. ä¸ºæ¯ä¸ªå¥å­åˆ†é…åˆé€‚çš„éŸ³è‰²ç±»å‹ï¼š
   - **male**: ç”·æ€§è§’è‰²å¯¹è¯ã€ç”·æ€§å†…å¿ƒç‹¬ç™½
   - **female**: å¥³æ€§è§’è‰²å¯¹è¯ã€å¥³æ€§å†…å¿ƒç‹¬ç™½  
   - **narrator**: ç¯å¢ƒæè¿°ã€å™è¿°æ–‡å­—ã€æ— æ˜ç¡®æ€§åˆ«çš„å†…å®¹
4. è°ƒç”¨ generate_audio_and_srt å·¥å…·ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶

åˆ†æè§„åˆ™ï¼š
- ç›´æ¥å¯¹è¯ç”¨å¼•å·åŒ…å›´ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­è¯´è¯è€…æ€§åˆ«
- å†…å¿ƒç‹¬ç™½é€šå¸¸ä»¥"å¿ƒæƒ³"ã€"æš—è‡ª"ç­‰è¯æ±‡å¼€å¤´
- ç¯å¢ƒæè¿°ã€åŠ¨ä½œæè¿°ä½¿ç”¨narratoréŸ³è‰²
- ä¿æŒå¥å­å®Œæ•´æ€§ï¼Œåœ¨æ ‡ç‚¹ç¬¦å·å¤„è‡ªç„¶æ–­å¥
- æ¯ä¸ªå¥å­20-50å­—ä¸ºå®œï¼Œè¿‡é•¿éœ€è¦æ‹†åˆ†

è¯·å…ˆè¯»å–è„šæœ¬ï¼Œç„¶ååˆ†æå¹¶ç”ŸæˆéŸ³é¢‘æ–‡ä»¶ã€‚
"""


@talk_agent.tool
def read_scene_script(ctx: RunContext[TalkAgentDeps]) -> str:
    """è¯»å–æŒ‡å®šåœºæ™¯çš„è„šæœ¬å†…å®¹"""
    scene_id = ctx.deps.scene_id
    scenes_file = "output/scenes.json"
    
    if not os.path.exists(scenes_file):
        return f"âŒ åœºæ™¯æ–‡ä»¶ä¸å­˜åœ¨: {scenes_file}"
    
    try:
        with open(scenes_file, "r", encoding="utf-8") as f:
            scenes_data = json.load(f)
        
        # æŸ¥æ‰¾æŒ‡å®šåœºæ™¯
        for scene in scenes_data:
            if scene.get("scene_id") == scene_id:
                script = scene.get("script", "")
                if not script:
                    return f"âŒ åœºæ™¯ {scene_id} çš„è„šæœ¬å†…å®¹ä¸ºç©º"
                
                return f"""åœºæ™¯ {scene_id} è„šæœ¬å†…å®¹ï¼š

{script}

å­—ç¬¦æ•°: {len(script)}

è¯·åˆ†ææ­¤è„šæœ¬ï¼ŒæŒ‰è¯­ä¹‰æ‹†åˆ†å¥å­å¹¶åˆ†é…éŸ³è‰²ï¼Œç„¶åè°ƒç”¨ generate_audio_and_srt å·¥å…·ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•ã€‚"""
        
        return f"âŒ æœªæ‰¾åˆ°åœºæ™¯ {scene_id} çš„æ•°æ®"
        
    except Exception as e:
        return f"âŒ è¯»å–åœºæ™¯æ–‡ä»¶å¤±è´¥: {str(e)}"


@talk_agent.tool
def generate_audio_and_srt(ctx: RunContext[TalkAgentDeps], segments: List[TalkAgentOutput]) -> str:
    """ä¸ºåˆ†æåçš„å¥å­ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶"""
    scene_id = ctx.deps.scene_id
    
    if not segments:
        return f"âŒ åœºæ™¯ {scene_id} æ²¡æœ‰æœ‰æ•ˆçš„è¯­å¥æ®µè½"
    
    # éªŒè¯æ•°æ®
    valid_segments = []
    for seg in segments:
        if seg.text.strip():
            valid_segments.append((seg.text.strip(), seg.voice_type))
    
    if not valid_segments:
        return f"âŒ åœºæ™¯ {scene_id} æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹"
    
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        audio_dir = "output/audio"
        srt_dir = "output/srt"
        os.makedirs(audio_dir, exist_ok=True)
        os.makedirs(srt_dir, exist_ok=True)
        
        # ç”Ÿæˆæ¯ä¸ªå¥å­çš„éŸ³é¢‘å’Œå­—å¹•
        audio_files, srt_files = generate_sentence_audio_and_srt(
            valid_segments, 
            "output", 
            scene_id
        )
        
        if not audio_files:
            return f"âŒ åœºæ™¯ {scene_id} éŸ³é¢‘ç”Ÿæˆå¤±è´¥"
        
        # åˆå¹¶éŸ³é¢‘æ–‡ä»¶
        merged_audio_path = os.path.join(audio_dir, f"scene_{scene_id}.wav")
        audio_result = merge_audio_files(audio_files, merged_audio_path)
        
        # åˆå¹¶SRTæ–‡ä»¶
        merged_srt_path = os.path.join(srt_dir, f"scene_{scene_id}.srt")
        srt_result = merge_srt_files(srt_files, merged_srt_path)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in audio_files + srt_files:
            try:
                if os.path.exists(temp_file):
                    os.remove(temp_file)
            except Exception:
                pass
        
        # ç»Ÿè®¡éŸ³è‰²ä½¿ç”¨æƒ…å†µ
        voice_stats = {}
        for _, voice_type in valid_segments:
            voice_stats[voice_type] = voice_stats.get(voice_type, 0) + 1
        
        stats_str = ", ".join([f"{voice}: {count}å¥" for voice, count in voice_stats.items()])
        
        return f"""âœ… åœºæ™¯ {scene_id} éŸ³é¢‘å’Œå­—å¹•ç”Ÿæˆå®Œæˆ:

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
- å¥å­æ€»æ•°: {len(valid_segments)}
- éŸ³è‰²åˆ†å¸ƒ: {stats_str}

ğŸ“ è¾“å‡ºæ–‡ä»¶:
- éŸ³é¢‘: {merged_audio_path}
- å­—å¹•: {merged_srt_path}

ğŸ”§ å¤„ç†ç»“æœ:
- {audio_result}
- {srt_result}"""
        
    except Exception as e:
        return f"âŒ ç”ŸæˆéŸ³é¢‘å’Œå­—å¹•å¤±è´¥: {str(e)}"